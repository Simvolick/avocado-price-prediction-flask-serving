{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2758de54-ff45-4414-8c90-87f0929f6ffc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/klimyadrintsev/anaconda3/lib/python3.7/site-packages (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/klimyadrintsev/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.21.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/klimyadrintsev/anaconda3/lib/python3.7/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/klimyadrintsev/anaconda3/lib/python3.7/site-packages (from tensorflow) (3.3.0)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc0ec17ba90>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /simple/gast/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc0ec195290>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /simple/gast/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc0ec16c850>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /simple/gast/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc0ec1806d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /simple/gast/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc0ec180310>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /simple/gast/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc0ec172350>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /simple/tensorflow/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc0ec15fa10>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /simple/tensorflow/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc0ec15fa90>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /simple/tensorflow/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc0ec165b10>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /simple/tensorflow/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc0ec1659d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /simple/tensorflow/\u001b[0m\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement gast<0.5.0,>=0.2.1 (from tensorflow) (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for gast<0.5.0,>=0.2.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27283f2d-fb26-4174-81cd-962af98ccf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import keras as K\n",
    "import keras.layers as Dense\n",
    "import keras.models as Sequential\n",
    "import keras.optimizers as Adam\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a52719b-4839-4fe0-a80f-c22bccee5283",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = 'sqlite:///../data_v2/avocado.db'\n",
    "data = pd.read_sql('SELECT * FROM avocado', data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19510be7-b083-42c6-82c2-39c8ca8a15bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.7</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.5</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.0</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.4</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.6</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2015-11-22</td>\n",
       "      <td>1.26</td>\n",
       "      <td>55979.78</td>\n",
       "      <td>1184.27</td>\n",
       "      <td>48067.99</td>\n",
       "      <td>43.61</td>\n",
       "      <td>6683.91</td>\n",
       "      <td>6556.47</td>\n",
       "      <td>127.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2015-11-15</td>\n",
       "      <td>0.99</td>\n",
       "      <td>83453.76</td>\n",
       "      <td>1368.92</td>\n",
       "      <td>73672.72</td>\n",
       "      <td>93.26</td>\n",
       "      <td>8318.86</td>\n",
       "      <td>8196.81</td>\n",
       "      <td>122.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2015-11-08</td>\n",
       "      <td>0.98</td>\n",
       "      <td>109428.33</td>\n",
       "      <td>703.75</td>\n",
       "      <td>101815.36</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6829.22</td>\n",
       "      <td>6266.85</td>\n",
       "      <td>562.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>1.02</td>\n",
       "      <td>99811.42</td>\n",
       "      <td>1022.15</td>\n",
       "      <td>87315.57</td>\n",
       "      <td>85.34</td>\n",
       "      <td>11388.36</td>\n",
       "      <td>11104.53</td>\n",
       "      <td>283.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2015-10-25</td>\n",
       "      <td>1.07</td>\n",
       "      <td>74338.76</td>\n",
       "      <td>842.4</td>\n",
       "      <td>64757.44</td>\n",
       "      <td>113.0</td>\n",
       "      <td>8625.92</td>\n",
       "      <td>8061.47</td>\n",
       "      <td>564.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date AveragePrice Total Volume     4046       4225   4770  \\\n",
       "0  0  2015-12-27         1.33     64236.62  1036.74   54454.85  48.16   \n",
       "1  1  2015-12-20         1.35     54876.98   674.28   44638.81  58.33   \n",
       "2  2  2015-12-13         0.93    118220.22    794.7  109149.67  130.5   \n",
       "3  3  2015-12-06         1.08     78992.15   1132.0   71976.41  72.58   \n",
       "4  4  2015-11-29         1.28      51039.6   941.48   43838.39  75.78   \n",
       "5  5  2015-11-22         1.26     55979.78  1184.27   48067.99  43.61   \n",
       "6  6  2015-11-15         0.99     83453.76  1368.92   73672.72  93.26   \n",
       "7  7  2015-11-08         0.98    109428.33   703.75  101815.36   80.0   \n",
       "8  8  2015-11-01         1.02     99811.42  1022.15   87315.57  85.34   \n",
       "9  9  2015-10-25         1.07     74338.76    842.4   64757.44  113.0   \n",
       "\n",
       "  Total Bags Small Bags Large Bags XLarge Bags          type  year  region  \n",
       "0    8696.87    8603.62      93.25         0.0  conventional  2015  Albany  \n",
       "1    9505.56    9408.07      97.49         0.0  conventional  2015  Albany  \n",
       "2    8145.35    8042.21     103.14         0.0  conventional  2015  Albany  \n",
       "3    5811.16     5677.4     133.76         0.0  conventional  2015  Albany  \n",
       "4    6183.95    5986.26     197.69         0.0  conventional  2015  Albany  \n",
       "5    6683.91    6556.47     127.44         0.0  conventional  2015  Albany  \n",
       "6    8318.86    8196.81     122.05         0.0  conventional  2015  Albany  \n",
       "7    6829.22    6266.85     562.37         0.0  conventional  2015  Albany  \n",
       "8   11388.36   11104.53     283.83         0.0  conventional  2015  Albany  \n",
       "9    8625.92    8061.47     564.45         0.0  conventional  2015  Albany  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6774f3e1-2ba5-4412-8a69-ab3db4f2c80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[: , 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1100b57b-8dd7-41c5-a76f-0e700563763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperating the prices to be predicted\n",
    "y = data.AveragePrice\n",
    "data.drop(['AveragePrice'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36174f1b-a934-438a-95e1-ab3bf7bd2cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74841686-0110-4811-8549-7991c79c062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype({'Date': 'object', 'Total Volume' : 'float64', '4046' : 'float64', '4225' : 'float64', '4770' : 'float64', 'Total Bags' : 'float64', 'Small Bags' : 'float64', 'Large Bags' : 'float64', 'XLarge Bags' : 'float64', 'type' : 'object', 'year' : 'int', 'region':'object' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "920ffe21-e3e1-4e0e-9b79-3d676f09f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "#splitting the data into training and test datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainflights, testflights, ytrain, ytest = train_test_split(data, y, train_size=0.7,test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fb9d62d-91a6-44b9-8d95-98403829b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (trainflights.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "n = (trainflights.dtypes == ('float64','int64'))\n",
    "numerical_cols = list(n[n].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d1df36b-371d-48f2-b87d-97ae1adfbbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'type', 'region']\n"
     ]
    }
   ],
   "source": [
    "#checking the columns containing categorical columns:\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feec4ea6-8743-4d25-b91e-4e2a912de0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using One Hot Encoder to make the categorical columns usable\n",
    "\n",
    "oneHot = OneHotEncoder(handle_unknown = 'ignore', sparse=False)\n",
    "oneHottrain = pd.DataFrame(oneHot.fit_transform(trainflights[object_cols]))\n",
    "oneHottest = pd.DataFrame(oneHot.transform(testflights[object_cols]))\n",
    "\n",
    "#reattaching index since OneHotEncoder removes them:\n",
    "oneHottrain.index = trainflights.index\n",
    "oneHottest.index = testflights.index \n",
    "\n",
    "#dropping the old categorical columns:\n",
    "cattraincol = trainflights.drop(object_cols, axis=1)\n",
    "cattestcol = testflights.drop(object_cols, axis=1)\n",
    "\n",
    "#concatenating the new columns:\n",
    "trainflights = pd.concat([cattraincol, oneHottrain], axis=1)\n",
    "testflights = pd.concat([cattestcol, oneHottest], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7137f20e-e768-419d-93c4-3a670c6e7563",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the values\n",
    "\n",
    "trainf = trainflights.values\n",
    "testf = testflights.values\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "\n",
    "trainflights = minmax.fit_transform(trainf)\n",
    "testflights = minmax.transform(testf)\n",
    "\n",
    "#defining a way to find Mean Absolute Percentage Error:\n",
    "def PercentError(preds, ytest):\n",
    "  error = abs(preds - ytest)\n",
    "\n",
    "  errorp = np.mean(100 - 100*(error/ytest))\n",
    "\n",
    "  print('the accuracy is:', errorp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1f1e284-391b-4a9b-8fdc-4c8a82dce7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   14.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0, verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#implementing the algo:\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0, verbose=1)\n",
    "\n",
    "#fitting the data to random forest regressor:\n",
    "model.fit(trainflights, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "783ea4ec-c734-43bf-ba69-a0d2f719de5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "#predicting the test dataset:\n",
    "preds = model.predict(testflights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f79c1312-7019-4195-b0ed-65579d1445e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest = ytest.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbe0ca49-20ef-4c5f-ac9d-b0bca32517b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is: 92.16058342518716\n"
     ]
    }
   ],
   "source": [
    "PercentError(preds, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64f54d64-13e7-4267-8e7e-c533a5af2cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using linear regression:\n",
    "LinearModel = LinearRegression()\n",
    "LinearModel.fit(trainflights, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95200552-88d2-44c9-a51e-0b2596bd323a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy is: 87.47226428609468\n"
     ]
    }
   ],
   "source": [
    "#predicting on the test dataset:\n",
    "LinearPredictions = LinearModel.predict(testflights)\n",
    "PercentError(LinearPredictions, ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2e8716-66b7-43eb-999a-3a31f58c2939",
   "metadata": {},
   "source": [
    "I got to this point but I think that train_test_split is not allowed to be used on time series data. I am pretty sure that this is not time series data but it is very similar region wise I guess. Let's just assume that data is not time correlated in any way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cdfd9d-9b78-45a7-8dc6-1cf2876e8d2b",
   "metadata": {},
   "source": [
    "On the other hand how can it not be correlated? As we know what the price will be in August and in December, predicting the price in the October is much easier that way, that is why maybe just going for the train test split scews the correctness of the predictions by a long shot. What if I use TimeSeriesSplit instead?TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc3b5812-e912-4ff2-8799-10698f53893b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model, open('../data_v2/model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5b4b5b-c96f-44f1-b5e8-0f6e4e867a74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
